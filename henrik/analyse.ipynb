{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this cell to transform raw file from bb to file without the non-utf8 characters �**\n",
    "\n",
    "Removes � characters from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in read mode, read its contents, then close it\n",
    "with open('../data/disaster-tweets.csv', 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Remove all � characters\n",
    "content = content.replace('�', '')\n",
    "\n",
    "# Open the file in write mode and write the modified content back to it\n",
    "with open('../data/disaster-tweets.csv', 'w', encoding='utf-8') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw data (10876, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>choose_one</th>\n",
       "      <th>choose_one:confidence</th>\n",
       "      <th>choose_one_gold</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>tweetid</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778243823</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778243824</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  778243823     True      golden                 156               NaN   \n",
       "1  778243824     True      golden                 152               NaN   \n",
       "\n",
       "  choose_one  choose_one:confidence choose_one_gold keyword location  \\\n",
       "0   Relevant                    1.0        Relevant     NaN      NaN   \n",
       "1   Relevant                    1.0        Relevant     NaN      NaN   \n",
       "\n",
       "                                                text  tweetid  userid  \n",
       "0                 Just happened a terrible car crash      1.0     NaN  \n",
       "1  Our Deeds are the Reason of this #earthquake M...     13.0     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '../data/disaster-tweets.csv'\n",
    "# read csv, \",\"-separated\n",
    "\n",
    "df = pd.read_csv(data_path, sep=',')\n",
    "\n",
    "# print dimensions\n",
    "print(\"Shape of raw data\", df.shape)\n",
    "\n",
    "# print first 2 rows\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save text, id to csv\n",
    "df[['text', 'tweetid']].to_csv('texts.csv', index=False, sep=';')\n",
    "\n",
    "# save all relevant rows to csv, i.e. choose_one = Relevant\n",
    "df[df['choose_one'] == 'Relevant'][['text', 'tweetid', 'location']].to_csv('relevant.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_unit_id                     0\n",
       "_golden                      0\n",
       "_unit_state                  0\n",
       "_trusted_judgments           0\n",
       "_last_judgment_at           84\n",
       "choose_one                   0\n",
       "choose_one:confidence        0\n",
       "choose_one_gold          10789\n",
       "keyword                     87\n",
       "location                  3638\n",
       "text                         0\n",
       "tweetid                      0\n",
       "userid                      87\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n",
    "\n",
    "# missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = ['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
    "       '_last_judgment_at', 'choose_one', 'choose_one:confidence',\n",
    "       'choose_one_gold', 'keyword', 'location', 'text', 'tweetid', 'userid']\n",
    "\n",
    "features_to_keep = [ 'choose_one', 'keyword', 'location', 'text' ]\n",
    "\n",
    "df = df[features_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  y\n",
       "0     NaN      NaN                 Just happened a terrible car crash  1\n",
       "1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...  1\n",
       "2     NaN      NaN  Heard about #earthquake is different cities, s...  1\n",
       "3     NaN      NaN  there is a forest fire at spot pond, geese are...  1\n",
       "4     NaN      NaN             Forest fire near La Ronge Sask. Canada  1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with choose_one = 'Can't Decide'\n",
    "df = df[df['choose_one'] != \"Can't Decide\"]\n",
    "\n",
    "# if choose one is relevant, set to 1, else 0\n",
    "df['choose_one'] = df['choose_one'].apply(lambda x: 1 if x == 'Relevant' else 0)\n",
    "\n",
    "df['y'] = df['choose_one']\n",
    "df.drop(columns=['choose_one'], inplace=True, errors='ignore')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions after preprocessing (10860, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason may allah forgive us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard different cities stay safe everyone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword location                                               text  y\n",
       "0     NaN      NaN                        happened terrible car crash  1\n",
       "1     NaN      NaN                  deeds reason may allah forgive us  1\n",
       "2     NaN      NaN          heard different cities stay safe everyone  1\n",
       "3     NaN      NaN  forest fire spot pond geese fleeing across str...  1\n",
       "4     NaN      NaN              forest fire near la ronge sask canada  1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "tokenizer = TweetTokenizer(\n",
    "    preserve_case=False,\n",
    "    strip_handles=True,\n",
    "    reduce_len=True,\n",
    ")\n",
    "\n",
    "Stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def remove_noise(doc):\n",
    "    filter_words = []\n",
    "\n",
    "    doc = doc.replace('�', '')\n",
    "\n",
    "    # # Remove URLs\n",
    "    doc = re.sub(r'http\\S+', '', doc)\n",
    "    doc = re.sub(r'www\\.\\S+', '', doc)\n",
    "\n",
    "    tokenized = tokenizer.tokenize(doc)\n",
    "\n",
    "    for word in tokenized:\n",
    "        if (word not in Stopwords \n",
    "            and word not in string.punctuation \n",
    "            and not word.startswith('#')\n",
    "            ):\n",
    "\n",
    "            filter_words.append(word)\n",
    "\n",
    "    return \" \".join(filter_words)\n",
    "    \n",
    "\n",
    "df['text'] = df['text'].apply(remove_noise)\n",
    "\n",
    "print(\"Dimensions after preprocessing\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv where y=1\n",
    "df[df['y'] == 1][['text', 'location']].to_csv('preprocessed_relevant.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (10860, 16340)\n",
      "Shape of X_train (8688, 16340)\n",
      "Shape of X_test (2172, 16340)\n",
      "Shape of y_train (8688,)\n",
      "Shape of y_test (2172,)\n"
     ]
    }
   ],
   "source": [
    "# Implement bag of words\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "\n",
    "bow = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "print(\"Shape of X\", bow.shape)\n",
    "\n",
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df['y'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train\", X_train.shape)\n",
    "print(\"Shape of X_test\", X_test.shape)\n",
    "print(\"Shape of y_train\", y_train.shape)\n",
    "print(\"Shape of y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42, solver='lbfgs').fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "# get probabilities for class 1\n",
    "y_pred = y_pred[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.7808471454880295\n",
      "Precision on the test set: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "clipped_y_pred = np.array([1 if x >= 0.5 else 0 for x in y_pred])\n",
    "\n",
    "accuracy = accuracy_score(y_test, clipped_y_pred)\n",
    "print(\"Accuracy on the test set:\", accuracy)\n",
    "\n",
    "precision = precision_score(y_test, clipped_y_pred, pos_label=1)\n",
    "\n",
    "print(\"Precision on the test set:\", precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6979</th>\n",
       "      <td>hiroshima</td>\n",
       "      <td>2.358691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>fires</td>\n",
       "      <td>2.313306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15919</th>\n",
       "      <td>wildfire</td>\n",
       "      <td>2.163371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15108</th>\n",
       "      <td>typhoon</td>\n",
       "      <td>2.098453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>bombing</td>\n",
       "      <td>2.039975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>derailment</td>\n",
       "      <td>2.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11720</th>\n",
       "      <td>rainstorm</td>\n",
       "      <td>1.865599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>1.826262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13891</th>\n",
       "      <td>storm</td>\n",
       "      <td>1.808118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>evacuated</td>\n",
       "      <td>1.792753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>debris</td>\n",
       "      <td>1.691063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10488</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>1.679711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7834</th>\n",
       "      <td>japan</td>\n",
       "      <td>1.648905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6641</th>\n",
       "      <td>hailstorm</td>\n",
       "      <td>1.640701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>drought</td>\n",
       "      <td>1.598397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12302</th>\n",
       "      <td>rioting</td>\n",
       "      <td>1.580440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>casualties</td>\n",
       "      <td>1.527942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>heat</td>\n",
       "      <td>1.526834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13084</th>\n",
       "      <td>shooting</td>\n",
       "      <td>1.525804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>massive</td>\n",
       "      <td>1.513089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature    weight\n",
       "6979    hiroshima  2.358691\n",
       "5738        fires  2.313306\n",
       "15919    wildfire  2.163371\n",
       "15108     typhoon  2.098453\n",
       "2217      bombing  2.039975\n",
       "4236   derailment  2.003807\n",
       "11720   rainstorm  1.865599\n",
       "4847   earthquake  1.826262\n",
       "13891       storm  1.808118\n",
       "5255    evacuated  1.792753\n",
       "4058       debris  1.691063\n",
       "10488    outbreak  1.679711\n",
       "7834        japan  1.648905\n",
       "6641    hailstorm  1.640701\n",
       "4731      drought  1.598397\n",
       "12302     rioting  1.580440\n",
       "2814   casualties  1.527942\n",
       "6844         heat  1.526834\n",
       "13084    shooting  1.525804\n",
       "9102      massive  1.513089"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map weights to vocabulary\n",
    "weights = clf.coef_[0]\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "feature_weights = pd.DataFrame({'feature': feature_names, 'weight': weights})\n",
    "\n",
    "feature_weights.sort_values(by='weight', ascending=False, inplace=True)\n",
    "\n",
    "feature_weights.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\skole\\it3212datadrevet\\it3212\\henrik\\analyse.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/skole/it3212datadrevet/it3212/henrik/analyse.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/skole/it3212datadrevet/it3212/henrik/analyse.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_test \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[\u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m\u001b[39m*\u001b[39mm):]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/skole/it3212datadrevet/it3212/henrik/analyse.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_test[\u001b[39m'\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m y_pred\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/skole/it3212datadrevet/it3212/henrik/analyse.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m incorrectly_classified_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(y_pred \u001b[39m!=\u001b[39m y_test)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_test = df.iloc[int(0.8*m):]\n",
    "\n",
    "df_test['y_pred'] = y_pred\n",
    "\n",
    "incorrectly_classified_indices = np.where(y_pred != y_test)[0]\n",
    "\n",
    "# select rows df incorrectly_classified_indices\n",
    "df_test.iloc[incorrectly_classified_indices].to_csv('results/incorrectly_classified_rows.csv', index=False)\n",
    "\n",
    "# false negatives\n",
    "false_negatives = np.where((y_pred == 0) & (y_test == 1))[0]\n",
    "\n",
    "df_test.iloc[false_negatives].to_csv('results/false_negatives.csv', index=False)\n",
    "\n",
    "# false positives\n",
    "\n",
    "false_positives = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "\n",
    "df_test.iloc[false_positives].to_csv('results/false_positives.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdt-4173-ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
